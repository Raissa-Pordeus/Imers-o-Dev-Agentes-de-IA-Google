{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Agentes de IA\n",
        "##Importação do LangChain"
      ],
      "metadata": {
        "id": "km0ATgYpO8ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cOYrdqBlG7IS"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "DX0jJ7fnH6Wn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature=0,#a temperatua pode variar entre 0 e 1\n",
        "    #quanto mais alta a temperatura, mais detalhada é a resposta\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "MA27VSU1TvWL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test = llm.invoke(\"Qual a capital do Brasil?\")\n"
      ],
      "metadata": {
        "id": "3vlW-B_9P-RX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp_test.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nP-YxPPQT95",
        "outputId": "950ad465-c87e-49e5-8ef3-d18dea223a54"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A capital do Brasil é **Brasília**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT=(\n",
        "    #detalhar situação/dar contexto\n",
        ")"
      ],
      "metadata": {
        "id": "eQ3_GGRjUESA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "  decisao:Literal[\"\"]#opções de decisão\n",
        "  urgencia:Literal[\"\"]#grau de urgência\n",
        "  campos_faltantes:List[str] = Field(default=list)"
      ],
      "metadata": {
        "id": "klOs0BBLUTw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(#poderia usar o llm definido anteriormente\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature=0,#a temperatua pode variar entre 0 e 1\n",
        "    #quanto mais alta a temperatura, mais detalhada é a resposta\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "bOhgbkTiU9La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Diferenciar mensagens do sistema e do usuário"
      ],
      "metadata": {
        "id": "bD2hmvj8Vh-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "triagem_chain = llm_triagem.with_structure_output(TriagemOut)\n",
        "def triagem(mensagem: str) -> Dict:\n",
        "  saida = TriagemOut = triagem_chain.invoke([\n",
        "      SystemMessage(content=TRIAGEM_PROMPT),\n",
        "      HumanMessage(content=mensagem)\n",
        "  ])\n",
        "\n",
        "  return saida.model_dump()"
      ],
      "metadata": {
        "id": "THnsjeDbVUoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bloco de Testes"
      ],
      "metadata": {
        "id": "YN3zByAfXCzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testes = []#escreve perguntas para testes"
      ],
      "metadata": {
        "id": "ztaf5LgCW9bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bloco de envio de Testes para a IA"
      ],
      "metadata": {
        "id": "n9MbavUiXOVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes:\n",
        "  print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\")"
      ],
      "metadata": {
        "id": "XVCpovnWXNps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}